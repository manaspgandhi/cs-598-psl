{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS598 PSL — Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Members: Rahul Kasibhatla, Neeyati Devanagondi, Manas Gandhi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Size                                                                                 Selected variables  Predicition error (mse)\n",
      "    1                                                                            (ontarget_scoring_att,)             6.521076e+11\n",
      "    2                                                                     (sub_on, ontarget_scoring_att)             6.295688e+11\n",
      "    3                                                              (sub_on, goals, ontarget_scoring_att)             6.243642e+11\n",
      "    4                                             (height, cm, weight, kg, sub_on, ontarget_scoring_att)             6.186855e+11\n",
      "    5                                      (height, cm, weight, kg, sub_on, goals, ontarget_scoring_att)             6.131527e+11\n",
      "    6                          (height, cm, weight, kg, sub_on, goals, aerial_won, ontarget_scoring_att)             6.091227e+11\n",
      "    7           (height, cm, weight, kg, sub_on, goals, aerial_won, ontarget_scoring_att, total_offside)             6.099922e+11\n",
      "    8 (height, cm, weight, kg, sub_on, goals, yellow_card, won_tackle, aerial_won, ontarget_scoring_att)             6.164107e+11\n"
     ]
    }
   ],
   "source": [
    "# (a) Fit a best subset selection algorithm to the data set and report the best model of each\n",
    "# model size (up to 8 variables, excluding the intercept) and their prediction errors. Make\n",
    "# sure that you simplify your output to only present the essential information.\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_df = pd.read_csv(\"mls_test.csv\")\n",
    "train_df = pd.read_csv(\"mls_train.csv\")\n",
    "\n",
    "y_train = train_df[\"salary\"]\n",
    "X_train = train_df.drop(columns=[\"salary\"])\n",
    "\n",
    "y_test = test_df[\"salary\"]\n",
    "X_test = test_df.drop(columns=[\"salary\"])\n",
    "\n",
    "results = []\n",
    "\n",
    "for k in range(1, 9): \n",
    "    best_mse = np.inf\n",
    "    best_vars = None\n",
    "    \n",
    "    for combo in itertools.combinations(X_train.columns, k):\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train[list(combo)], y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test[list(combo)])\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_vars = combo\n",
    "\n",
    "    results.append({\n",
    "        \"Size\": k,\n",
    "        \"Selected variables\": best_vars,\n",
    "        \"Predicition error (mse)\": best_mse\n",
    "    })\n",
    "\n",
    "\n",
    "results_a = pd.DataFrame(results)\n",
    "print(results_a.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to AIC-- Best Model: ['height, cm', 'weight, kg', 'sub_on', 'goals', 'yellow_card', 'won_tackle', 'aerial_won', 'ontarget_scoring_att'] | Train MSE: 296811761763.0 | Test MSE: 616410698050.296\n",
      "According to BIC-- Best Model: ['sub_on', 'ontarget_scoring_att'] | Train MSE: 309434842063.795 | Test MSE: 629568772715.585\n",
      "According to Cp-- Best Model: ['height, cm', 'weight, kg', 'sub_on', 'goals', 'yellow_card', 'won_tackle', 'aerial_won', 'ontarget_scoring_att'] | Train MSE: 296811761763.0 | Test MSE: 616410698050.296\n",
      "According to Adj-R2-- Best Model: ['height, cm', 'weight, kg', 'sub_on', 'goals', 'yellow_card', 'won_tackle', 'aerial_won', 'ontarget_scoring_att'] | Train MSE: 296811761763.0 | Test MSE: 616410698050.296\n"
     ]
    }
   ],
   "source": [
    "# (b) Using the models reported in part (a), which is the best model acording to: (i) AIC, (ii)\n",
    "# BIC, (iii) Cp-Mallows, and (iv) R2a? For each criterion, report the MSE for both training and testing data.\n",
    "\n",
    "# AIC\n",
    "best_aic, best_model_aic = np.inf, None\n",
    "for row in results_a.itertuples(index=False):\n",
    "    vars_ = list(row[1])\n",
    "    k = len(vars_)\n",
    "    lm = LinearRegression().fit(X_train[vars_], y_train)\n",
    "    yhat_train = lm.predict(X_train[vars_])\n",
    "    rss_train = np.sum((y_train - yhat_train)**2)\n",
    "    curr_aic = len(y_train) * np.log(rss_train/len(y_train)) + 2*k\n",
    "    \n",
    "    if curr_aic < best_aic:\n",
    "        best_aic = curr_aic\n",
    "        best_model_aic = (vars_,\n",
    "                          mean_squared_error(y_train, yhat_train),\n",
    "                          mean_squared_error(y_test, lm.predict(X_test[vars_])))\n",
    "\n",
    "print(\"According to AIC-- Best Model:\", best_model_aic[0], \"| Train MSE:\", round(best_model_aic[1],3), \"| Test MSE:\", round(best_model_aic[2],3))\n",
    "\n",
    "\n",
    "# BIC\n",
    "best_bic, best_model_bic = np.inf, None\n",
    "for row in results_a.itertuples(index=False):\n",
    "    vars_ = list(row[1])\n",
    "    k = len(vars_)\n",
    "    lm = LinearRegression().fit(X_train[vars_], y_train)\n",
    "    yhat_train = lm.predict(X_train[vars_])\n",
    "    rss_train = np.sum((y_train - yhat_train)**2)\n",
    "    bic = len(y_train) * np.log(rss_train/len(y_train)) + k*np.log(len(y_train))\n",
    "    if bic < best_bic:\n",
    "        best_bic = bic\n",
    "        best_model_bic = (vars_,\n",
    "                          mean_squared_error(y_train, yhat_train),\n",
    "                          mean_squared_error(y_test, lm.predict(X_test[vars_])))\n",
    "\n",
    "print(\"According to BIC-- Best Model:\", best_model_bic[0], \"| Train MSE:\", round(best_model_bic[1],3), \"| Test MSE:\", round(best_model_bic[2],3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cp\n",
    "full_model = LinearRegression().fit(X_train, y_train)\n",
    "rss_full = np.sum((y_train - full_model.predict(X_train))**2)\n",
    "sigma2_hat = rss_full / (len(y_train) - X_train.shape[1] - 1)\n",
    "\n",
    "best_cp, best_model_cp = np.inf, None\n",
    "for row in results_a.itertuples(index=False):\n",
    "    vars_ = list(row[1])\n",
    "    k = len(vars_)\n",
    "    lm = LinearRegression().fit(X_train[vars_], y_train)\n",
    "    yhat_train = lm.predict(X_train[vars_])\n",
    "    rss_train = np.sum((y_train - yhat_train)**2)\n",
    "    cp = rss_train/sigma2_hat + 2*k - len(y_train)\n",
    "\n",
    "    if cp < best_cp:\n",
    "        best_cp = cp\n",
    "        best_model_cp = (vars_,\n",
    "                         mean_squared_error(y_train, yhat_train),\n",
    "                         mean_squared_error(y_test, lm.predict(X_test[vars_])))\n",
    "\n",
    "print(\"According to Cp-- Best Model:\", best_model_cp[0],\"| Train MSE:\", round(best_model_cp[1],3), \"| Test MSE:\", round(best_model_cp[2],3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# R2\n",
    "tss = np.sum((y_train - np.mean(y_train))**2)\n",
    "\n",
    "best_r2, best_model_r2 = -np.inf, None\n",
    "for row in results_a.itertuples(index=False):\n",
    "    vars_ = list(row[1])\n",
    "    k = len(vars_)\n",
    "    lm = LinearRegression().fit(X_train[vars_], y_train)\n",
    "    yhat_train = lm.predict(X_train[vars_])\n",
    "    rss_train = np.sum((y_train - yhat_train)**2)\n",
    "    adj_r2 = 1 - (rss_train/(len(y_train)-k-1)) / (tss/(len(y_train)-1))\n",
    "    if adj_r2 > best_r2:\n",
    "        best_r2 = adj_r2\n",
    "        best_model_r2 = (vars_,\n",
    "                         mean_squared_error(y_train, yhat_train),\n",
    "                         mean_squared_error(y_test, lm.predict(X_test[vars_])))\n",
    "\n",
    "print(\"According to Adj-R2-- Best Model:\", best_model_r2[0], \"| Train MSE:\", round(best_model_r2[1],3), \"| Test MSE:\", round(best_model_r2[2],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best λ: 3511.1917342151346\n",
      "Ridge Regression -- Train MSE: 254511446399.33725 | Test MSE: 661842279049.4984\n"
     ]
    }
   ],
   "source": [
    "# (c) Fit a ridge regression model to predict a player’s salary. Use cross-validation to select\n",
    "# the best regularization parameter λ.\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lambdas = np.logspace(-3, 5, 100)  \n",
    "\n",
    "ridge_cv = RidgeCV(alphas=lambdas, store_cv_values=True)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "best_lambda = ridge_cv.alpha_\n",
    "\n",
    "yhat_train = ridge_cv.predict(X_train)\n",
    "yhat_test = ridge_cv.predict(X_test)\n",
    "train_mse = mean_squared_error(y_train, yhat_train)\n",
    "test_mse = mean_squared_error(y_test, yhat_test)\n",
    "\n",
    "print(\"Best λ:\", best_lambda)\n",
    "print(\"Ridge Regression -- Train MSE:\", train_mse, \"| Test MSE:\", test_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best λ: 6135.907273413176\n",
      "Lasso Regression -- Train MSE: 250848266779.776 | Test MSE: 642991348132.554\n",
      "Features shrunk to zero: ['height, cm', 'game_started', 'mins', 'yellow_card']\n"
     ]
    }
   ],
   "source": [
    "# (d) Fit a lasso regression model on the same data set. Identify which features are shrunk to\n",
    "# zero.\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "lambdas = np.logspace(-3, 5, 100)  \n",
    "\n",
    "lasso_cv = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LassoCV(alphas=np.logspace(-3, 5, 100), cv=5, max_iter=10000, random_state=42)\n",
    ")\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "best_lambda = lasso_cv.named_steps['lassocv'].alpha_\n",
    "\n",
    "yhat_train = lasso_cv.predict(X_train)\n",
    "yhat_test = lasso_cv.predict(X_test)\n",
    "train_mse = mean_squared_error(y_train, yhat_train)\n",
    "test_mse = mean_squared_error(y_test, yhat_test)\n",
    "coef = lasso_cv.named_steps['lassocv'].coef_\n",
    "features = X_train.columns\n",
    "zero_features = [f for f, c in zip(features, coef) if c == 0]\n",
    "\n",
    "print(\"Best λ:\", best_lambda)\n",
    "print(\"Lasso Regression -- Train MSE:\", round(train_mse,3),\"| Test MSE:\", round(test_mse,3))\n",
    "print(\"Features shrunk to zero:\", zero_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Compare the performance of the models in (b) vs. ridge vs. lasso using the MSE. Which model would you recommend for predicting MLS player salaries and why?\n",
    "\n",
    "Based on MSE, I would recommend the subset 6-varaible model from part b with an MSe OF 6.091227 × 10^11."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
